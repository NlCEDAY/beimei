## 模型评估--如何评价模型：

### 一：为什么要评估模型？

> 学习器在训练时会出现**欠拟合和过拟合**现象，**模型对此与真实模型会产生误差**。

- `训练误差：`

  > 学习器在训练集上的误差

- `泛化误差：`

  > 学习器在新的样本上产生的误差
  >
  > 泛化能力：指学习器对新样本的适应能力

### 二：怎样用科学的手段评估模型？

> 面对泛化误差评估，我们需要使用一个**与训练集互斥的验证集**来测试学习器对新样本的判别能力，并且用这个**验证误差近似作为泛化误差**。

#### 1）留出法：

> 将数据集D划分为两个互斥的集合，一个为训练集S，一个为验证集T
>
> tips：训练与测试集的数据要尽量保证数据分布一致，避免数据划分偏差造成结果误差。

- `分层采样：`

  > 保证数据分布一致，我们可以对每个类别进行比例采样
  >
  > 一般2/3~4/5作为训练集，剩下作为测试集。

#### 2）交叉验证：

> 将数据集D划分为k个大小相似的互斥子集，子集保证数据分布一致，选取k-1个子集的并集作为训练集，1一个作为测试集，这样轮换着做k组，最终去返回k个测试结果的均值

![image-20200830131132484](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200830131132484.png)

#### 3）自助法--bootstrapping：

> 以自助采样法（有放回）为基础，给定m个样本的数据集D：每次随机从D中挑选一个样本放入D‘，并将样本放回D，重复m次。
>
> 在数据集较小，难以划分训练/测试集的情况很有用。

样本在m次采样中始终不被采到的概率为：
$$
（1-\frac{1}{m}）^m
$$
取极限：
$$
\lim_{m->∞}（1-\frac{1}{m}）^m=\frac{1}{e}≈0.368
$$
我们有36.8%的样本未在D’中出现，我们可以将D‘作为训练集，选取36.8%未出现在D'的样本作为测试集。

**缺点：** 改变了初始数据集的分布，会引入估计偏差，数据量足够，交叉验证比较常用。

### 三：从哪些方面去评估模型？

> 我们通过对数据集的一些手段去找到了评估模型的科学方法，我们需要从哪些方面考虑做评判，从不同的评判标准去评判一个模型的好坏，往往能得出不同的结果。
>
> 在此，我们考虑有哪些评判标准去评价一个模型

#### 1）错误率和精度：

> 适用于二分类与多分类任务

- `错误率：`

  > 分类错误的样本数占样本总数的比例

  $$
  E(f;D)=\frac{1}{m}\sum_{i=1}^m∏(f(x_i)≠y_i)
  $$

- `精度：`

  > 分类正确的样本数占样本总数的比例

  $$
  acc(f;D)=\frac{1}{m}\sum_{i=1}^m∏(f(x_i)=y_i)=1-E(f;D)
  $$

#### 2）查准率，查全率与F1：

> 在需求作为信息检索和web搜索时，我们不重点关心上面两个性能，我们对检测的信息的比例多少是用户所感兴趣的，用户感兴趣的有多少被检索出来了，我们对此创新出查准和查全率

- `查全率：`

  >指**检出的相关文献量与检索系统中相关文献总量的比率**
  >
  >是衡量信息检索系统检出**相关文献能力的尺度**

- `查准率：`

  > 指**检出的相关文献量与检出文献总量的比率**
  >
  > 是衡量信息检索系统检出**文献准确度的尺度**



在面对二分类问题中，我们通过**混淆矩阵**查看**查准率P与查全率R**的直观定义：

> TP：true postive
>
> FN：false negative

<table>
	<tr>
	    <th rowspan="2" align="center">真实情况</th>
	    <th colspan="2" align="center">预测结果</th>
	</tr>
	<tr>
	    <td align="center">正例</td>
	    <td align="center">反例</td>
	</tr>
	<tr>
	    <td align="center">正例</td>
	    <td align="center">TP</td>
        <td align="center">FN</td>
	</tr>
	<tr>
	    <td align="center">反例</td>
	    <td align="center">FP</td>
        <td align="center">TN</td>
	</tr>
</table>

$$
P=\frac{TP}{TP+FP}\\  R=\frac{TP}{TP+FN}
$$

> 查准率更关注完全正确的结果**占预测情况为正确结果**的比重
>
> 查全率更关注完全正确的结果**占真实情况是正确结果**的比重
>
> 假设癌症是正例，医生可能会发生两种错误，本来患癌的人被判不换癌（去真错误，正例被判反FN），本来不换癌的人被判患癌（取伪错误，反例被判正FP），
>
> 我门更希望尽量去真错误少FN，FN减少，FP就有可能增加，医生还是更关注查全率，
>
> 查全率为基于真实情况的准确率，宁可错杀不可放过一个
>
> 查准率·为基于预测情况的准确率，百发百中

下图边际情况描述不准确，仅仅表达去真错误和取伪错误往往是负相关

![image-20200830143041339](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200830143041339.png)

上图为查全率和查准率的关系图，他们两者通过混淆矩阵可以看出，往往是此消彼长的关系。

当一个学习器A的P-R曲线明显包于另一个学习器B时，我们认为A优于B`

- `F1与Fβ:`

  > F1基于查准率与查全率的调和平均
  >
  > Fβ基于查准率与查全率的加权调和平均

$$
F1=\frac{1}{2}*(\frac{1}{P}+\frac{1}{R})\\
F_β=\frac{1}{1+β^2}*(\frac{1}{P}+\frac{β^2}{R})
$$

> 很显然：
>
> 我们做推荐系统希望用户看到的是用户喜欢的，避免出现不喜欢的，更注重''准''
>
> 我们做逃犯检索系统希望一个都不漏，宁可错杀，不可放过，更注重''全''
>
> 所以查准查全，依情况而定。

#### 3）ROC与AUC：

- `ROC：`

  > Receiver Operating Characteristic -- 受试者工作特征
  >
  > 研究学习器泛化能力的有效工具

  与查准查全不同，它的横纵坐标分别为：
  $$
  纵轴：真正例率（True Positive Rate ）--TPR=\frac{TP}{TP+FN}——预测后正真样本占真实正确分类的比例--真实正例中有多少预测对了，宁可错杀不可放过一个，\\
  横轴：假正例率（False Positive Rate ）--FPR=\frac{FP}{TN+FP}——预测后正假样本占真实错误分类的比例--真实负例中有多少预测错了，变成了正例，我错杀了几个占真实负例的比率
  $$
  当我们不断调整判别正反样本的阈值时，就会得到不同的横纵点，最后完成ROC的绘制
  
  （1，1）点是我全判正（查全率最极端的情况），想要查全率拿到100%是可以的，只要我极端一点全判正就行了
  
  （0，0）点是我全判负（（查全率最极端的情况），想要查全率拿到0%是可以的，只要我极端一点全判负就行了）
  
  做实验就是我不断将判断正的比率增加，直至全判断正，画出来的ROC曲线

![image-20200830162408854](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200830162408854.png)

**ROC与P-R的区别：**

>总所周知：roc与p-r只是**评判模型好坏的两种衡量标准**
>
>但是P-R有一点问题，就是在**正负样本明显数量相差很大**时，负样本特别多的情况下，它的**查全率（召回）查到负样本的概率明显增大**，产生了测试集样本分布本身对模型性能评估造成了影响。
>
>而roc不会。

![image-20200830173220174](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200830173220174.png)

> P-R比ROC更关注正样本，而ROC兼顾两者，根据业务需求选择两者。

- `AUC:`

  > AUC(Area Under Curve)即指ROC曲线下面积占总方格的比例.

  $$
  AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}+x_i)(y_i+y_{i+1})
  $$

  而AUC的反面面积，很显然就是损失程度了，所以AUC越大，性能越好

#### 4）代价敏感错误率与代价曲线：

> 很显然，现实更加复杂，往往我们犯得不同种类的错误，付出的代价往往是不同的，你误判一个没有患癌的人患癌相比你误判一个患癌的人没患癌，后者的造成的问题严重性更大。
>
> 所以代入现实生活，我们对于每一种错误，在之前的性能度量上需要加上非均等代价。

- `代价敏感错误率：`

$$
E(f;D;cost)=\frac{1}{m}\sum_{xi∈D^+}I(f(xi)≠yi)×cost_{01}+\sum_{xi∈D^−}I(f(xi)≠yi)×cost_{10}
$$

- `代价曲线横轴：`
  $$
  P(+)=\frac{p*cost_{0|1}}{p*cost_{0|1}+(1-p)*cost_{1|0}}
  $$
  
- `代价曲线纵轴：`
  $$
  cost_{norm}=\frac{FNR*p*cost_{0|1}+FPR*(1-p)*cost_{1|0}}{p*cost_{0|1}+(1-p)*cost_{1|0}}=FNR*P(+)+FPR*(1-P(+))
  $$
  

  > 查找资料后：
  >
  > 令cost10=C(+|−)cost10=C(+|−)表示实际为反例但预测成正例的代价 
  > 令cost01=C(−|+)cost01=C(−|+)表示实际为正例但是预测为反例的代价

![image-20200830200758626](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200830200758626.png)

> 按照周教授的书上所说，围成的面积为**所有条件下学习器的期望总体代价。**

这里推导和来源较为繁琐，且来源较少，之后重新写一章来专门概述。

### 四：比较检验

> 下章再写
## 线性回归算法：

![image-20200824185034518](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824185034518.png)
$$
hm
$$

### 误差项分析：

![image-20200824185448774](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824185448774.png)

![image-20200824185644212](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824185644212.png)

#### 非常重要的概念：

- 每个误差ε(i)是**独立**并且具有**相同分布**，并且**服从均值为0**方差为θ^2的高斯分布
  - **独立：**张三和李四来贷款，他两没关系，主体上的样本点都是无关系的。
  - **同分布：** 他俩来的都是我们假定的同一家银行，分析的是同一个主体
  - **高斯分布：** 银行 可能会多给，也可能会少给，**但是绝大多数情况下，浮动不会太大，极小情况浮动比较大**



### 似然函数求解：

  

![image-20200824190809042](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824190809042.png)

误差项=真实值-预测值

而误差项本身又服从高斯分布

#### 似然函数：

> 根据你的样本去估 计你的特征参数的真实值，似然估计
>
> 例如你调查赌场，你的样本 



##### 最大似然估计：

当我们列出了当某个特征的条件下得到真实值的概率，

我们将所有的特征的概率情况相乘，变成似然函数

> 似然函数就变成了我们的最后判断的情况，
>
> 每个特征的概率就好像是调查赌场，你问的其中一个人的赚不赚钱的概率，
>
> 而你需要判断全面，所以我要对所有特征考虑进去，
>
> 将每个人看成独立同分布（同一赌场，人与人之间无关），相乘最后产生一个似然函数

我们希望似然函数越大越好，及我们需要求最大似然估计（最大的概率），认为这就是这样的参数θ就是接近真实值的可能。

##### 对数似然：

> 我们由于是乘法求解似然函数，乘法很难求解，通过对数的方式将乘法变成加法便于求解

### 



![image-20200824190936529](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824190936529.png)

### 目标函数推导：                      

![image-20200824195339245](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824195339245.png)

![image-20200824195557598](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824195557598.png)

最小二乘法的由来：

### 线性回归求解：

![image-20200824200418173](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824200418173.png)

![image-20200824200425307](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824200425307.png)

求偏导：--为了求什么样的θ使表达式越小越好，也就是求表达式最小值，需要使偏导等于0

> X是我们的数据，y是结果标签值

一种求最值得方法：线性回归

### 评估方法：

- R^2评估项：残差平方和越小越好

![image-20200824201320775](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824201320775.png)

> 当误差有可能不服从高斯分布，因为原始数据存在一些偏度，

### Logistic regression

> 逻辑回归得决策边界，可以是非线性，解决经典二分类算法

![image-20200824232124191](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824232124191.png)

用线性回归得到的值，映射到sigmoid上将值变成概率转换

我们将大于0.5得我们认为是一种情况，小于0.5是另一种情况。

![image-20200824232540548](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824232540548.png)

### Logistic regression 求解

![image-20200824233059669](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824233059669.png)

![image-20200824233757845](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824233757845.png) 

![image-20200824234331772](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200824234331772.png)
## DDIA读书笔记--分布式数据系统设计的目的：

本书分三个部分

1.数据是系统的基石

2.分布式数据

3.派生数据

### 数据系统的分类：

> **数据库和消息队列和高速缓存**我们通常视为**不同的数据系统**，他们看上去很相似（保存数据和处理数据），但是他们**有着不同的访问模式**，意味着有着**不同的设计实现和性能特征**

#### 不同的业务场景：

>  无论是数据库还是消息队列还是高速缓存，我们通常是遇到不同的场景问题。
>
> 1.如果查寻数据时我们通常使用高速缓存，提前先存一波需要查询的高频数据，
>
> 2.如果当缓存未命中时，我们需要从数据库中读取，并持久化写入数据库，
>
> 3.如果我们查询文章的词语，需要用另类的全文索引的方式查找，
>
> 4.如果用户数请求数过多，我们需要将异步任务放入消息队列去做一个缓冲

### 设计数据系统三大目的：

#### 宕机仍可正常运转--可靠性：Reliability

> 即希望系统能正常工作，即使我出现故障也有很好的容错性。

从三个方面判断软件是否能正常运转：

- application preforms the function that the user expected(用户所需要的功能正常)
- it can tolerate the user making mistakes or using the software in unexpected ways.（软件错误的使用方法或者用户发生错误时正常）
- its performance is good enough for the required use case,under the expected load and data volume.（在一些令人期待的压力下，能够很好的运转）
- the system prevents any unauthorized access and abuse（系统能组织非授权的访问）

##### Hardware Faults--软件错误

> 当机器很多时，这种错误经常发生

随者数据和应用计算需求增加时，很多应用会打算使用更多数量的机器，而这一增加了硬件错误的可能性，而且，在一些云平台虚拟机实例通常没有预警就会无法使用，随着平台被设计灵活性和超出了单机最大可靠性能。



因此系统可以容忍整个机器的损耗，通过使用一些软件容错计数来增加一些硬件忍耐性。这样的系统同时又一些额外的优点，当如果你需要重启机器时，一个单服务系统需要计划离机时间。当一个系统可以容忍机器错误在一段时间被patched在一个节点上，不需要整个系统都关机。

##### 可靠性的重要性：

##### Software Errors

我峨嵋你通常想硬件错误都是彼此独立且随机的，一个硬件硬盘无措不会去imply另外一个机器的硬盘错误，这之间都是些微弱的关联，并且不可能在同一时间大量的硬件出现错误

还要一类错误时系统性的错误，这样的错误更难去预测，因为节点直接是相互联系的，他们却会造成更多没有任何关联的硬件错误



这些bug造成这些软件错误通常会欺骗很长一段时间到当一个比较常见的情形下他们这些错误就会被触发，在这些情形下，软件产生了很大假设关于，它最终停止因为一些理由。

对于软件上的一些系统性错误没有很快的解决办法。但是右很多小tips可以帮助：可以通过测试，进程隔离，使进程crash和重启，计算监控和分析系统在生产中的行为。如果一个系统

#### 未来仍可正常运转--可扩展性：Scalability



as the system grows(in data volume,traffic



#### 运转时维护方便--可维护性：

- **数据存储系统**

  > 

- **数据处理系统**

> 
>
> 一个可能出错的事物与一个不可能出错的事物之间的**主要区别**是：当一个不可能出错的事物出错了，通常也就意味着不可修复。

### 可靠性：



### 可扩展性：

> 考虑到未来的工作可拓展性，当负载增加时，看是否能正常运行

#### 负载描述：

- 可能是web服务器的每秒请求处理次数
- 数据库写入的比例
- 聊天室的同时活动用户数量
- 缓存命中率

#### 性能描述：

- 吞吐量：每秒可处理的记录条数
- 延迟与响应时间：（通常考察平均响应时间）
- 较高的响应时间百分位数：（长尾效应）

#### 应对负载增加的办法：

> 先做垂直扩展，如果出了问题就继续做水平扩展
>
> 需要取舍的因素有，数据读取量，写入量，待存储的数据量，数据的复杂程度，响应时间要求，访问模型

- 垂直扩展：--升级更强悍的机器

- 水平扩展：--将负载分布到更小的机器



### 可维护性：

> 维护与缺陷修复，监控系统来保持正常运行，故障排查，适配新平台，搭配新场景，计数缺陷的完善以及增加新功能。

#### 简单性：

#### 可演化性：

#### 可运维性：

### 数据模型有哪些？

> 使用通用数据模型JSON，XML文档

#### 文档模型：

> 

#### 关系模型:

> 将实现细节隐藏在更简洁的接口后面--商业数据处理

#### 对象-关系不匹配：

>  现在都是面向对象的编程语言，当应用层代码的对象和表行列模型之间需要一个转换层，成为**阻抗失谐**。

#### 当一对多关系处理：

- 传统数据sql模型
- xml格式
- json格式

#### 多对一和多对多关系处理：

> 对于文档模型就很不适合了，关系型和图模型都比较适合



### 数据该如何存储？

hash（降低了写的效率，大大增加了读的效率，无法解决范围查询）

lsm tree（范围查询，进一步牺牲写的效率，增加了读的效率）

b+ tree（最大化读的效率）

列式存储

### 数据应该长什么样？（编码格式）

普通文本

特定协议

特定格式（需要解码和编码，压缩）

### 从三性出发，引出分布式系统的架构？

#### 水平拓展（复制副本和分区）

复制的意义：高可用，容错，低延迟，可拓展

复制的方案：单领导者，多领导者，无领导者

#### 同一份数据分散到不同的机器

分区方式：hash分区，范围分区（hbase做得很好）

分区再平衡：

请求路由

#### 事务

隔离级别：脏读，脏写，不可重复读，更新丢失，写倾斜，幻读

实现可串行化隔离级别：严格串行执行事务，两阶段锁，可串行化快照隔离

#### 分布式的问题？

不可靠的网络（主要的麻烦）

不可靠的时钟

没有统一的共识

#### 分布式如何看起来像单机？

##### 一致性和共识：

cas寄存器

原子事务提交

全序广播

锁和租约

成员/协调服务

唯一性约束

### 派生系统：流，批

#### 核心问题：

容错

数据分片

#### unix哲学：

mapreduce

### join：

排序合并连接

广播散列连接

分区散列连接

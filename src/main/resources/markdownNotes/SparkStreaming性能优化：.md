## SparkStreaming性能优化：

### 一：优化运行时间：

#### 1.增加并行度

> 确保使用整个集群的资源，不要把任务集中在某几个节点上，
>
> 对于shuffle的操作，**增加其并行度**来充分使用资源

#### 2.减少数据序列化，反序列化的负担

> SparkStreaming默认将接收到的数据 **序列化后**在存储，来减少内存使用
>
> 为了减少cpu负担，因此我们使用**Kryo序列化方式** 或者 **自定义序列化接口**

#### 3.设置合理的batch duration（批处理时间）

> SparkStreaming中，Job之间可能存在依赖关系，job必须 按照顺序递进执行，若上游的job超过了批处理时间，那么下游的job也会无法按时提交，然后不断往后job拖延，因此一定要设置合理，作业一定能在该时间间隔内完成

#### 4.减少因任务提交和分发所带来的负担

> Akka框架可以高效保证任务及时分发
>
> 担当批处理间隔非常小<500ms,提交和分发任务的延迟就显得不可忽视了
>
> 使用 Standalone和Coarse-grained Mesos模式通常会比使用Fine-grained Mesos模式有更小的延迟

### 二：优化内存使用：

#### 1.控制batch size （批处理时间间隔内的数据量）

> Spark Streaming 会把批处理时间间隔收到的数据全部放在Spark内的内存里，因此必须确保当前节点可用内存能容奶间隔内的所有数据。

#### 2.及时清理不再使用的数据

> Spark Streaming 会将接受的数据全部存储到内部可用内存区域，但不会说我这个批处理处理过就清理掉
>
> 所以对于不需要的数据即使清理，通过设置合理的spark.cleaner.ttl时长来即使清理超时的无用数据。

#### 3.观察及时调整GC策略

> GC会影响Job的正常运行，可能延长Job的执行时间，引起一系列不可预料的问题。
>
> 采用不同的GC策略减小内存回收对Job运行的影响。
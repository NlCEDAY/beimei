## Kafka性能优化：

### 消费者参数优化：

1. `enable.auto.commit`

   > 指定了消费者是否自动提交偏移量，默认值是true，
   >
   > 为了尽量避免重复数据和数据丢失，**可以把它设置为false**，有自己控制提交偏移量
   >
   > true可以通过设置`auto.commit.interval.ms`来控制提交频率

2. `auto.offset.reset`

   > 该参数指定了消费者在读取一个没有offset或者offset无效的分区的情况下，
   >
   > 默认值是latest，就是从最新记录读取数据（消费者启动之后生成的记录）
   >
   > 另一个值为earliest，意思是在偏移量无效情况下，消费者从起始位置开始去读取数据。

3. `session.timeout.ms`

   > 该参数指定了**当消费者被认为已经挂掉之前可以与服务器断开连接的时间**，**默认为3s**，消费者在3s之内没有再次向服务器发送心跳，那么将会被认为已经死亡。
   >
   > 此时，协调器会触发再均衡，把他的分区分配给其他的消费者，该参数与`heartbeat.interval.ms`紧密相关，该参数定义了消费者发送心跳的时间间隔，也就是**心跳频率**，一般要同时修改这两个参数，
   >
   > heartbeat.interval.ms 参数值必须要小于 session.timeout.ms，一般是 session.timeout.ms 的三分之一，
   >
   > 比如，session.timeout.ms 设置成 3min，那么 heartbeat.interval.ms 一般设置成 1min，这样，可以更快的检测以及恢复崩溃的节点，不过长时间的轮询或垃圾收集可能导致非预期的再均衡（有一种情况就是网络延迟，本身消费者是没有挂掉的，但是网络延迟造成了心跳超时，这样本不该发生再均衡，但是因为网络原因造成了非预期的再均衡），把该参数的值设置得大一些，可以减少意外的再均衡，不过检测节点崩溃需要更长的时间。

4. `max.partition.fetch.bytes`

   > 参数指定了**服务器从每个分区里返回给消费者的最大字节数**，它的默认值**是1mb**，也就是说，kafkaConsumer.poll()方法从每个分区返回的记录最多不超过max.paritions.fetch.bytes指定的字节。
   >
   > 如果一个主题有20个分区和5个消费者，那么每个消费者需要至少4MB的可用内存来接受记录。
   >
   > 因此在为消费者分配内存时，可以给他们呢多分配一些，因为群组里由消费者挂掉，那么就需要更多的内存区处理分区。
   >
   > **tips： ** **max.partition.fetch.bytes的值必须比Broker能够接收的最大消息的字节数**（通过max.message.size属性配置）大，否则消费者可能无法读取消息，导致消费者一直挂起重试，
   >
   > 例如，max.message.size设置为2MB，而该属性设置为1MB，**那么当一个生产者可能就会生产一条大小为2MB的消息**，然后消费者能拉的最大的消息就只有1MB，数据消息确实2MB，会拉不了导致消费者一直挂起重试。
   >
   > 在设置该属性时，另一个需要**考虑的因素是消费者处理数据的时间**，消费者需要频繁调用poll（）方法来避免会话过期和发生分区再均衡，如果单次调用poll（）返回的数据太多，消费者需要更多的时间来处理，很有可能无法及时进行下一个轮询来避免会话过期，入宫出现这种情况，可以把max.partition.fetch.bytes值改小，或延长会话过期时间。

   

5. `fetch.min.bytes`

   > 消费者**从服务器获取记录的最小字节数**，Broker收到消费者拉取数据的请求的时候，如果可用数据量小于设置的值,那么Broker将会等待有足够可用的数据的时候才返回给消费者，这样可以降低消费者和Broker的工作负载。
   >
   > 因为当主题不是很活跃的情况下，就不需要来来回回的处理消息，如果没有很多可用数据，但消费者的CPU使用率却很高，那么就需要把**该属性的值设的比默认值大**。
   >
   > 如果消费者的数量比较多，把该属性的值设置的大一点可以降低Broker的工作负载。
## 项目编写：

训练数据集放到HDFS里（等到数据集都送到位了，时间和数据）

约定一点半送过来，放宽一个小时，凌晨2点半送过来，没有特殊数据处理会ooize定时检查hdfs得文件和数据，有的话就进行调度，还会把数据放到kafka

sla（service ）

进hbase数据集是为了训练和优化得模型得数据集（进hbase是因为数据量非常大，而且hbase内置有去重，有可能导入hive会有大量小文件，streaming会有小文件）

通过sparkStreaming从kafka里来test拿出来做预测

![image-20200924085308828](C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200924085308828.png)

用kafkastreams进行格式转换和简单得数据清洗，在这里kafka里用kafkastreaming比sparkstreaming速度快得多

